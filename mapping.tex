\chapter{Mapping}
\label{chap:mapping}
The Legion mapper interface is a key part
of the Legion programming system. Through the mapping interface applications
can control most decisions that can impact application performance.
The philosophy is that these choices are better left to applications
rather than using hard-wired heuristics in Legion that attempt to ``do the right thing'' in
every situation.  The few performance heuristics
that are included in Legion are associated with low levels of the system
where there is no good way to expose those choices to the application.
For everything else the policies can be set by the application.

This design resulted from our own past experience with systems
where built-in heuristics did not behave as we desired and there was no recourse
to override those decisions.  While this approach does not give experts the
option to tune runtime policies, it is very convenient for casual users
who don't need to learn how to set those policies. While Legion does allow
users to squeeze every last bit of performance from a system, it is important
to realize that doing so potentially requires understanding and setting a wide
variety of parameters exposed in the mapping interface.
This level of control can be overwheling at first to users who are not used to
considering all the possible dimensions that influence performance in complex,
distributed, and heterogeneous systems.

To help users write initial versions of their applications without needing
to concern themselves with tuning the performance knobs exposed by the mapper
interface, Legion provides a {\em default mapper}.  The default mapper
implements the Legion mapper API (like any other mapper) and provides a number
of heuristics that can provide reasonably performant, or at least correct, initial
settings.  A good way to think about the default mapper is that it is the version
of Legion with built-in heuristics that allows casual users to write Legion
applications or allows experts to start quickly on a new application.
As such, it is unreasonable to expect the default mapper to provide excellent performance, and in
particular assuming that the performance of an application using the default
mapper is even an approximation of the performance that could be
achieved with a custom mapper is a mistake.


We will use several examples from the default mapper
to illustrate how mappers are constructed. We will also describe where
possible the heuristics that the default mapper employs to achieve
reasonable performance. Because the default mapper uses generic heuristics
with no specific knowledge of the apllication, it is almost certain to make
poor decisions at least some of the time.
Performance benchmarking using only the default mapper is strongly
discouraged, while using custom application-specific mappers is
encouraged.

It is likely that the moment when you are dissatisfied with the 
heuristics in the default mapper will come sooner rather than later.
At that point the information in this chapter will be necessary for you
to write your own custom mapper.  In practice, our experience has been that in
many cases all that is necessary is to replace a small number of policies in the
default mapper that are a poor fit for the application.

\section{Mapper Organization}
\label{sec:mapping:org}

The Legion mapper interface is an abstract C++ class that defines a set of 
pure virtual functions that the Legion runtime invokes as callbacks
for making performance-related decisions. A Legion mapper is therefore 
simply a class that inherits from the base abstract class and provides 
implementations of the associated pure virtual methods.

\subsection{Mapper Registration}
\label{subsec:mapping:registration}

After the Legion runtime is created, but before the application itself
begins, the application is given the opportunity to register mapper objects 
with the runtime. Figure~\ref{fig:mapper_registration} gives a small
example demonstrating how to register a custom mapper.

\begin{figure}
\begin{lstlisting}
void top_level_task(const Task *task,
		    const std::vector<PhysicalRegion> &regions,
		    Context ctx, 
		    Runtime *runtime)
{
  printf("Running top level task...\n");
}

class CustomMapperA : public DefaultMapper {
public:
  CustomMapperA(MapperRuntime *rt, Machine m, Processor p)
    : DefaultMapper(rt, m, p) { }
public:
  static void register_custom_mappers(Machine machine, Runtime *rt,
                                      const std::set<Processor> &local_procs);
};

/*static*/
void CustomMapperA::register_custom_mappers(Machine machine, Runtime *rt,
                                            const std::set<Processor> &local_procs)
{
  printf("Replacing default mappers with custom mapper A on all processors...\n");
  MapperRuntime *const map_rt = rt->get_mapper_runtime();
  for (std::set<Processor>::const_iterator it = local_procs.begin();
       it != local_procs.end(); it++)
    {
      rt->replace_default_mapper(new CustomMapperA(map_rt, machine, *it), *it);
    }
}

class CustomMapperB : public DefaultMapper {
public:
  CustomMapperB(MapperRuntime *rt, Machine m, Processor p)
    : DefaultMapper(rt, m, p) { }
public:
  static void register_custom_mappers(Machine machine, Runtime *rt,
                                      const std::set<Processor> &local_procs);
};

/*static*/
void CustomMapperB::register_custom_mappers(Machine machine, Runtime *rt,
                                            const std::set<Processor> &local_procs) 
{
  printf("Adding custom mapper B for all processors...\n");
  MapperRuntime *const map_rt = rt->get_mapper_runtime();
  for (std::set<Processor>::const_iterator it = local_procs.begin();
       it != local_procs.end(); it++)
    {
      rt->add_mapper(1/*MapperID*/, new CustomMapperA(map_rt, machine, *it), *it);
    }
}

int main(int argc, char **argv)
{
  Runtime::set_top_level_task_id(TOP_LEVEL_TASK_ID);
  {
    TaskVariantRegistrar registrar(TOP_LEVEL_TASK_ID, "top_level_task");
    registrar.add_constraint(ProcessorConstraint(Processor::LOC_PROC));
    Runtime::preregister_task_variant<top_level_task>(registrar);
  }
  Runtime::add_registration_callback(CustomMapperA::register_custom_mappers);
  Runtime::add_registration_callback(CustomMapperB::register_custom_mappers);

  return Runtime::start(argc, argv);
}
\end{lstlisting}
\caption{\legionbook{Mapping/registration/registration.cc}}
\label{fig:mapper_registration}
\end{figure}

To register {\tt CustomMapper} objects, the
application adds the mapper callback function by invoking the
{\tt Runtime::add\_registration\_callback} method, which takes as an
argument a function pointer to be invoked. The function pointer must
have a specific type, taking as arguments a {\tt Machine} object, 
a {\tt Runtime} pointer, and a reference to an STL set of {\tt Processor}
objects. The call can be invoked multiple times to record multiple
callback functions (e.g., to register multiple custom mappers). All
callback functions must be added prior to the invocation of the 
{\tt Runtime::start} method. We recommend that applications include the registration
method as a static method on the mapper class (as in Figure~\ref{fig:mapper_registration})
so that it is closely coupled to the custom mapper itself.

Before invoking any of the callback functions, the runtime 
creates an instance of the default mapper for each processor of
the system. The runtime then invokes the callback functions in the order
they were added. Each callback function is invoked once on each 
instance of the Legion runtime. For multi-process jobs, there will be 
one copy of the Legion runtime per process and therefore one invocation
of each callback per process. The set of processors passed into each 
registration callback function will be the set of application processors 
that are local to the process\footnote{Mappers cannot be associated with
utility processors, and therefore utility processors are not included
in the set.}, thereby providing a registration callback
function with the necessary context to know which processors it
will create new custom mappers for. 
If no callback functions are registered then the only mappers
that will be available are instances of the default mapper associated
with each application processor.

Upon invocation, the registration callbacks should create instances
of custom mappers and associate them with application processors. 
This step can be done through one of two runtime mapper calls. The mapper
can replace the default mappers (always registered with {\tt MapperID}
0) by calling {\tt Runtime::replace\_default\_mapper}, whichis the
only way to replace the default mappers. Alternatively, the registration
callback can use {\tt Runtime::add\_mapper} to register a mapper with a
new {\tt MapperID}. Both the {\tt Runtime::replace\_default\_mapper} and
the {\tt Runtime::add\_mapper} methods support an optional processor
argument, which tells the runtime to associate the mapper with a specific
processor. If no processor is specified, the mapper will be associated 
with all processors on the local node. This choice is mapper-specific:
whether one mapper object should handle a single application processor's
mapping decisions, or whether it should handle the mapping decisions for
all application processors on a node. Legion supports both use cases
and it is up to custom mappers to make the best choice. From a performance
perspective, the best choice is likely to depend on the mapper synchronization
model (see Section~\ref{subsec:mapping:sync}).

When creating custom mappers, the registration callback should get a pointer
to the {\tt MapperRuntime} and pass it as an argument to all mapper objects.
The mapper runtime will provide the interface for mapper calls to call back
into the runtime to acquire access to different physical resources. We 
will see instances of the use of the mapper runtime throughout the rest of
the examples in this chapter.

\subsection{Synchronization Model}
\label{subsec:mapping:sync}

Within an instance of the Legion runtime there are often several threads
performing the analysis necessary to advance the execution of an
application. If some threads are performing work for operations 
owned by the same mapper, it is possible that they will attempt to 
invoke mapper calls for the same mapper object concurrently. For both 
productivity and correctness reasons, we do not want users to be
responsible for making their mappers thread-safe. Therefore we allow
mappers to specify a {\em synchronization model} which the runtime will
follow when concurrent mapper calls are made.

Each mapper object can specify its own synchronization model via the
{\tt get\_mapper\_sync\_model} mapper call. The runtime invokes this
method exactly once per mapper object immediately after the mapper is
registered with the runtime. Once the synchronization model has been set
for a mapper object it cannot be changed. Currently three
synchronization models are supported:

\begin{itemize}
\item Serialized Non-Reentrant - Calls to the
      mapper object are serialized and execute atomically. If the mapper 
      calls out to the runtime and the mapper call is preempted, 
      no other mapper calls can be invoked by the runtime.
      This synchronization model conforms to the original version of
      the Legion mapper interface.
\item Serialized Reentrant - At most one mapper call
      executes at a time. However, if a mapper call invokes a runtime
      method that preempts the mapper call, the runtime may
      execute another mapper call or resume a previously blocked
      mapper call. It is up to the user to handle any changes in internal mapper
      state that might occur while a mapper call is preempted (e.g., the
      invalidation of STL iterators to internal mapper data structures).
\item Concurrent - Mapper calls to the same mapper object can
      proceed concurrently. Users can invoke the {\tt lock\_mapper} and
      {\tt unlock\_mapper} calls to perform their own synchronization
      of the mapper. This synchronization model is particularly useful for
      mappers that simply return static mapping decisions
      without changing internal mapper state.
\end{itemize}

The mapper synchronization offers mappers tradeoffs between mapper complexity and performance. The default mapper uses the 
serialized reentrant synchronization model as it offers a good trade-off
between programmability and performance.

\subsection{Machine Interface}
\label{subsec:mapping:machine}

All mappers are given a {\tt Machine} object to enable
introspection of the hardware on which the application is executing. The
{\tt Machine} object is a Realm-level object;  see {\tt realm/machine.h}.

There are two interfaces for querying the machine
object. The old interface contains methods such as {\tt get\_all\_processors}
and {\tt get\_all\_memories}. These methods populate STL data structures
with the appropriate names of processors and memories. We {\bf strongly}
discourage users from using these methods as they are not scalable on large
architectures with tens to hundreds of thousands of processors or memories.

The recommended, and more efficient and scalable, interface is based
on {\em queries}, which come in two types: {\tt ProcessorQuery} and 
{\tt MemoryQuery}. Each query is initially given a reference to the machine
object. After initialization the query lazily materializes the (entire) set of 
either processors or memories of the machine.
The mapper applies {\em filters} to the query to reduce the
set to processors or memories of interest.  These filters can include specializing
the query on the kind of processors with the {\tt only\_kind} method or by
requesting that the processor or memory have a specific affinity to another
processor or memory with the {\tt has\_affinity\_to}. Affinity can either be
specified as a minimum bandwidth or a maximum latency. Figure~\ref{fig:mapper_machine}
shows how to create a custom mapper that uses queries to find the local set of 
processors with the same processor kind as and the memories with affinities to the local
mapper processor. In some cases, these queries are still expensive, so we
encourage the creation of mappers that memoize the results of their most 
commonly invoked queries to avoid duplicated work.

\begin{figure}
\begin{lstlisting}
void top_level_task(const Task *task,
		    const std::vector<PhysicalRegion> &regions,
		    Context ctx, 
		    Runtime *runtime)
{
  printf("Running top level task...\n");
}

class MachineMapper : public DefaultMapper {
public:
  MachineMapper(MapperRuntime *rt, Machine m, Processor p);
public:
  static void register_machine_mappers(Machine machine, Runtime *rt,
                                       const std::set<Processor> &local_procs);
};

MachineMapper::MachineMapper(MapperRuntime *rt, Machine m, Processor p)
  : DefaultMapper(rt, m, p)
{
  // Find all processors of the same kind on the local node
  Machine::ProcessorQuery proc_query(m);
  // First restrict to the same node
  proc_query.local_address_space();
  // Make it the same processor kind as our processor
  proc_query.only_kind(p.kind());
  for (Machine::ProcessorQuery::iterator it = proc_query.begin(); 
        it != proc_query.end(); it++)
  {
    // skip ourselves
    if ((*it) == p)
      continue;
    printf("Mapper %s: shares " IDFMT "\n", get_mapper_name(), it->id);
  }
  // Find all the memories that are visible from this processor
  Machine::MemoryQuery mem_query(m);
  // Find affinity to our local processor
  mem_query.has_affinity_to(p);
  for (Machine::MemoryQuery::iterator it = mem_query.begin();
        it != mem_query.end(); it++)
    printf("Mapper %s: has affinity to memory " IDFMT "\n", get_mapper_name(), it->id);
}

/*static*/
void MachineMapper::register_machine_mappers(Machine machine, Runtime *rt,
                                             const std::set<Processor> &local_procs)
{
  printf("Replacing default mappers with custom mapper A on all processors...\n");
  MapperRuntime *const map_rt = rt->get_mapper_runtime();
  for (std::set<Processor>::const_iterator it = local_procs.begin();
       it != local_procs.end(); it++)
    {
      rt->replace_default_mapper(new MachineMapper(map_rt, machine, *it), *it);
    }
}

int main(int argc, char **argv)
{
  Runtime::set_top_level_task_id(TOP_LEVEL_TASK_ID);
  {
    TaskVariantRegistrar registrar(TOP_LEVEL_TASK_ID, "top_level_task");
    registrar.add_constraint(ProcessorConstraint(Processor::LOC_PROC));
    Runtime::preregister_task_variant<top_level_task>(registrar);
  }
  Runtime::add_registration_callback(MachineMapper::register_machine_mappers);

  return Runtime::start(argc, argv);
}
\end{lstlisting}
\caption{\legionbook{Mapping/machine/machine.cc}}
\label{fig:mapper_machine}
\end{figure}


\section{Mapping Tasks}
\label{sec:mapping:tasks}

\subsection{Overview of the Task Mapping Pipeline}
select\_task\_options (once per task launch)
select\_tasks\_to\_map (until task gets added to list)
select\_sharding\_functor (once per task launch, if replicated execution)
slice\_task (if index launch, can recurse, includes only local points if replicated execution)
map\_task
select\_task\_sources (for each region requirement, to decide where to pull the data from, if more than one option)

\subsection{Task Placement}
\label{subsec:mapping:placement}

\subsection{Selecting Task Variants}
\label{subsec:mapping:variants}

\subsection{Creating Physical Instances}
\label{subsec:mapping:instances}

\subsection{Using Virtual Mappings}
\label{subsec:mapping:virtual}

\subsection{Profiling Requests}
\label{subsec:mapping:profiling}

\subsection{Resilience Support}
\label{subsec:mapping:resilience}



\section{Mapping Other Operations}
\label{sec:mapping:others}

\subsection{Mapping Copies}
\label{subsec:mapping:copies}

\subsection{Mapping Acquires and Releases}
\label{subsec:mapping:acquires}

\subsection{Mapping Must Epoch Launches}
\label{subsec:mapping:mustepoch}



\section{Managing Execution}
\label{sec:mapping:execution}

\subsection{Context Management}
\label{subsec:mapping:context}

\subsection{Mapper Communication}
\label{subsec:mapping:communication}

\subsection{Controlling Stealing}
\label{subsec:mapping:stealing}

\section{Mappers Included with Legion}

Default mapper

Logging mapper

Null mapper


